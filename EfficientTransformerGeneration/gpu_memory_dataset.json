[
    {
        "model_name": "meta-llama/Meta-Llama-3-8B-Instruct",
        "gpu_name": "NVIDIA A100-SXM4-80GB",
        "gpu_batch_size": 64,
        "gen_steps": 50,
        "max_input_token_factor": 20,
        "max_batch_factor": 20,
        "dataset": {
            "50": 1088,
            "100": 576,
            "150": 384,
            "200": 256,
            "250": 192,
            "300": 192,
            "350": 128,
            "400": 128,
            "450": 128,
            "500": 64
        }
    },
    {
        "model_name": "meta-llama/Meta-Llama-3-8B-Instruct",
        "gpu_name": "NVIDIA A100-SXM4-80GB",
        "gpu_batch_size": 64,
        "gen_steps": 150,
        "max_input_token_factor": 40,
        "max_batch_factor": 20,
        "dataset": {
            "50": 576,
            "100": 512,
            "150": 384,
            "200": 256,
            "250": 192,
            "300": 192,
            "350": 128,
            "400": 128,
            "450": 128,
            "500": 64,
            "550": 64,
            "600": 64,
            "650": 64,
            "700": 64,
            "750": 64,
            "800": 64,
            "850": 64,
            "900": 64,
            "950": 63,
            "1000": 60,
            "1050": 57,
            "1100": 54,
            "1150": 52,
            "1200": 50,
            "1250": 48,
            "1300": 46,
            "1350": 44,
            "1400": 42,
            "1450": 41,
            "1500": 40,
            "1550": 38,
            "1600": 37,
            "1650": 36,
            "1700": 35,
            "1750": 34,
            "1800": 33,
            "1850": 32,
            "1900": 31,
            "1950": 30,
            "2000": 30
        }
    }
]